<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Statistical Fundamentals | Data Analysis and Processing with R based on IBIS data</title>
  <meta name="description" content="7 Statistical Fundamentals | Data Analysis and Processing with R based on IBIS data" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Statistical Fundamentals | Data Analysis and Processing with R based on IBIS data" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="mushroom.jpg" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Statistical Fundamentals | Data Analysis and Processing with R based on IBIS data" />
  
  
  <meta name="twitter:image" content="mushroom.jpg" />

<meta name="author" content="Kevin Donovan" />


<meta name="date" content="2019-10-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="working-with-tables-in-r.html"/>
<link rel="next" href="regression-analysis-methods.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Index</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i><b>1.1</b> Preface</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html"><i class="fa fa-check"></i><b>2</b> Introducing R and Rstudio</a><ul>
<li class="chapter" data-level="2.1" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#intro"><i class="fa fa-check"></i><b>2.1</b> Intro</a></li>
<li class="chapter" data-level="2.2" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#why-use-r-for-data-analysis"><i class="fa fa-check"></i><b>2.2</b> Why use R for data analysis?</a></li>
<li class="chapter" data-level="2.3" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#r-and-rstudio-what-is-the-difference"><i class="fa fa-check"></i><b>2.3</b> R and RStudio: What is the difference?</a></li>
<li class="chapter" data-level="2.4" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>2.4</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="2.5" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#the-interface-of-rstudio"><i class="fa fa-check"></i><b>2.5</b> The interface of RStudio</a><ul>
<li class="chapter" data-level="2.5.1" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#console"><i class="fa fa-check"></i><b>2.5.1</b> Console</a></li>
<li class="chapter" data-level="2.5.2" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#scripts"><i class="fa fa-check"></i><b>2.5.2</b> Scripts</a></li>
<li class="chapter" data-level="2.5.3" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#rmd-files"><i class="fa fa-check"></i><b>2.5.3</b> RMD Files</a></li>
<li class="chapter" data-level="2.5.4" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#environment"><i class="fa fa-check"></i><b>2.5.4</b> Environment</a></li>
<li class="chapter" data-level="2.5.5" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#plots-packages-and-help"><i class="fa fa-check"></i><b>2.5.5</b> Plots, Packages, and Help</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introducing-r-and-rstudio.html"><a href="introducing-r-and-rstudio.html#file-directories-in-r"><i class="fa fa-check"></i><b>2.6</b> File Directories in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="objects-and-functions.html"><a href="objects-and-functions.html"><i class="fa fa-check"></i><b>3</b> Objects and Functions</a><ul>
<li class="chapter" data-level="3.1" data-path="objects-and-functions.html"><a href="objects-and-functions.html#intro-1"><i class="fa fa-check"></i><b>3.1</b> Intro</a></li>
<li class="chapter" data-level="3.2" data-path="objects-and-functions.html"><a href="objects-and-functions.html#functions"><i class="fa fa-check"></i><b>3.2</b> Functions</a></li>
<li class="chapter" data-level="3.3" data-path="objects-and-functions.html"><a href="objects-and-functions.html#objects"><i class="fa fa-check"></i><b>3.3</b> Objects</a></li>
<li class="chapter" data-level="3.4" data-path="objects-and-functions.html"><a href="objects-and-functions.html#object-classes-and-types"><i class="fa fa-check"></i><b>3.4</b> Object classes and types</a><ul>
<li class="chapter" data-level="3.4.1" data-path="objects-and-functions.html"><a href="objects-and-functions.html#vectors"><i class="fa fa-check"></i><b>3.4.1</b> Vectors</a></li>
<li class="chapter" data-level="3.4.2" data-path="objects-and-functions.html"><a href="objects-and-functions.html#matricies"><i class="fa fa-check"></i><b>3.4.2</b> Matricies</a></li>
<li class="chapter" data-level="3.4.3" data-path="objects-and-functions.html"><a href="objects-and-functions.html#lists"><i class="fa fa-check"></i><b>3.4.3</b> Lists</a></li>
<li class="chapter" data-level="3.4.4" data-path="objects-and-functions.html"><a href="objects-and-functions.html#data-frames"><i class="fa fa-check"></i><b>3.4.4</b> Data Frames</a></li>
<li class="chapter" data-level="3.4.5" data-path="objects-and-functions.html"><a href="objects-and-functions.html#types"><i class="fa fa-check"></i><b>3.4.5</b> Types</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="objects-and-functions.html"><a href="objects-and-functions.html#subsetting"><i class="fa fa-check"></i><b>3.5</b> Subsetting</a></li>
<li class="chapter" data-level="3.6" data-path="objects-and-functions.html"><a href="objects-and-functions.html#base-r"><i class="fa fa-check"></i><b>3.6</b> Base R</a></li>
<li class="chapter" data-level="3.7" data-path="objects-and-functions.html"><a href="objects-and-functions.html#environment-1"><i class="fa fa-check"></i><b>3.7</b> Environment</a></li>
<li class="chapter" data-level="3.8" data-path="objects-and-functions.html"><a href="objects-and-functions.html#putting-it-all-together-read.csv"><i class="fa fa-check"></i><b>3.8</b> Putting It All Together: read.csv</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="using-dplyr.html"><a href="using-dplyr.html"><i class="fa fa-check"></i><b>4</b> Using dplyr</a><ul>
<li class="chapter" data-level="4.1" data-path="using-dplyr.html"><a href="using-dplyr.html#intro-2"><i class="fa fa-check"></i><b>4.1</b> Intro</a></li>
<li class="chapter" data-level="4.2" data-path="using-dplyr.html"><a href="using-dplyr.html#dplyr-functions"><i class="fa fa-check"></i><b>4.2</b> dplyr Functions</a><ul>
<li class="chapter" data-level="4.2.1" data-path="using-dplyr.html"><a href="using-dplyr.html#select-filter-and-arrange"><i class="fa fa-check"></i><b>4.2.1</b> Select, filter, and arrange</a></li>
<li class="chapter" data-level="4.2.2" data-path="using-dplyr.html"><a href="using-dplyr.html#mutate-and-summarize"><i class="fa fa-check"></i><b>4.2.2</b> Mutate and summarize</a></li>
<li class="chapter" data-level="4.2.3" data-path="using-dplyr.html"><a href="using-dplyr.html#spread-gather-separate-and-unite"><i class="fa fa-check"></i><b>4.2.3</b> Spread, Gather, Separate and Unite</a></li>
<li class="chapter" data-level="4.2.4" data-path="using-dplyr.html"><a href="using-dplyr.html#renaming-variables"><i class="fa fa-check"></i><b>4.2.4</b> Renaming variables</a></li>
<li class="chapter" data-level="4.2.5" data-path="using-dplyr.html"><a href="using-dplyr.html#using-the-pipe"><i class="fa fa-check"></i><b>4.2.5</b> Using the pipe</a></li>
<li class="chapter" data-level="4.2.6" data-path="using-dplyr.html"><a href="using-dplyr.html#editing-factor-variables-recode-and-relevel"><i class="fa fa-check"></i><b>4.2.6</b> Editing factor variables: recode() and relevel()</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html"><i class="fa fa-check"></i><b>5</b> Creating Graphs With ggplot2</a><ul>
<li class="chapter" data-level="5.1" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#base-r-vs.-ggplot2"><i class="fa fa-check"></i><b>5.1</b> Base R vs. ggplot2</a></li>
<li class="chapter" data-level="5.2" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#ggplot2"><i class="fa fa-check"></i><b>5.2</b> ggplot2</a><ul>
<li class="chapter" data-level="5.2.1" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#introduction"><i class="fa fa-check"></i><b>5.2.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#ggplot-aesthetics"><i class="fa fa-check"></i><b>5.3</b> ggplot Aesthetics</a><ul>
<li class="chapter" data-level="5.3.1" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#scatterplot"><i class="fa fa-check"></i><b>5.3.1</b> Scatterplot</a></li>
<li class="chapter" data-level="5.3.2" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#colors-in-r"><i class="fa fa-check"></i><b>5.3.2</b> Colors in R</a></li>
<li class="chapter" data-level="5.3.3" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#line-of-best-fit"><i class="fa fa-check"></i><b>5.3.3</b> Line of best fit</a></li>
<li class="chapter" data-level="5.3.4" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#box-and-whisker"><i class="fa fa-check"></i><b>5.3.4</b> Box and whisker</a></li>
<li class="chapter" data-level="5.3.5" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#barchart"><i class="fa fa-check"></i><b>5.3.5</b> Barchart</a></li>
<li class="chapter" data-level="5.3.6" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#other-aesthetics"><i class="fa fa-check"></i><b>5.3.6</b> Other aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#additional-customization"><i class="fa fa-check"></i><b>5.4</b> Additional customization</a><ul>
<li class="chapter" data-level="5.4.1" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#titles-and-labels"><i class="fa fa-check"></i><b>5.4.1</b> Titles and Labels</a></li>
<li class="chapter" data-level="5.4.2" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#colors"><i class="fa fa-check"></i><b>5.4.2</b> Colors</a></li>
<li class="chapter" data-level="5.4.3" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#sizes-and-shapes"><i class="fa fa-check"></i><b>5.4.3</b> Sizes and shapes</a></li>
<li class="chapter" data-level="5.4.4" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#themes"><i class="fa fa-check"></i><b>5.4.4</b> Themes</a></li>
<li class="chapter" data-level="5.4.5" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#reversing-the-axes"><i class="fa fa-check"></i><b>5.4.5</b> Reversing the axes</a></li>
<li class="chapter" data-level="5.4.6" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#facets"><i class="fa fa-check"></i><b>5.4.6</b> Facets</a></li>
<li class="chapter" data-level="5.4.7" data-path="creating-graphs-with-ggplot2.html"><a href="creating-graphs-with-ggplot2.html#exporting-your-plot"><i class="fa fa-check"></i><b>5.4.7</b> Exporting your plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="working-with-tables-in-r.html"><a href="working-with-tables-in-r.html"><i class="fa fa-check"></i><b>6</b> Working with Tables in R</a><ul>
<li class="chapter" data-level="6.1" data-path="working-with-tables-in-r.html"><a href="working-with-tables-in-r.html#intro-3"><i class="fa fa-check"></i><b>6.1</b> Intro</a></li>
<li class="chapter" data-level="6.2" data-path="working-with-tables-in-r.html"><a href="working-with-tables-in-r.html#creating-basic-tables-table-and-xtabs"><i class="fa fa-check"></i><b>6.2</b> Creating Basic Tables: table() and xtabs()</a></li>
<li class="chapter" data-level="6.3" data-path="working-with-tables-in-r.html"><a href="working-with-tables-in-r.html#tabular-data-analysis"><i class="fa fa-check"></i><b>6.3</b> Tabular Data Analysis</a><ul>
<li class="chapter" data-level="6.3.1" data-path="working-with-tables-in-r.html"><a href="working-with-tables-in-r.html#tests-for-independence"><i class="fa fa-check"></i><b>6.3.1</b> Tests for Independence</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html"><i class="fa fa-check"></i><b>7</b> Statistical Fundamentals</a><ul>
<li class="chapter" data-level="7.1" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#intro-4"><i class="fa fa-check"></i><b>7.1</b> Intro</a></li>
<li class="chapter" data-level="7.2" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#statistical-inference"><i class="fa fa-check"></i><b>7.2</b> Statistical Inference</a><ul>
<li class="chapter" data-level="7.2.1" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#parameter-estimation-mean-median-tutorial-quantiles"><i class="fa fa-check"></i><b>7.2.1</b> Parameter Estimation: Mean, Median, tutorial, Quantiles</a></li>
<li class="chapter" data-level="7.2.2" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#accounting-for-estimation-variance-and-hypothesis-testing"><i class="fa fa-check"></i><b>7.2.2</b> Accounting for estimation variance and hypothesis testing</a></li>
<li class="chapter" data-level="7.2.3" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#confidence-intervals"><i class="fa fa-check"></i><b>7.2.3</b> Confidence intervals</a></li>
<li class="chapter" data-level="7.2.4" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#hypothesis-testing"><i class="fa fa-check"></i><b>7.2.4</b> Hypothesis testing</a></li>
<li class="chapter" data-level="7.2.5" data-path="statistical-fundamentals.html"><a href="statistical-fundamentals.html#hypothesis-testing-with-means"><i class="fa fa-check"></i><b>7.2.5</b> Hypothesis Testing with Means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html"><i class="fa fa-check"></i><b>8</b> Regression Analysis Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#intro-5"><i class="fa fa-check"></i><b>8.1</b> Intro</a></li>
<li class="chapter" data-level="8.2" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#linear-regression"><i class="fa fa-check"></i><b>8.2</b> Linear Regression</a><ul>
<li class="chapter" data-level="8.2.1" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#motivation"><i class="fa fa-check"></i><b>8.2.1</b> Motivation</a></li>
<li class="chapter" data-level="8.2.2" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#methodology"><i class="fa fa-check"></i><b>8.2.2</b> Methodology</a></li>
<li class="chapter" data-level="8.2.3" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#overview"><i class="fa fa-check"></i><b>8.2.3</b> Overview</a></li>
<li class="chapter" data-level="8.2.4" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#example-1-continuous-predictors"><i class="fa fa-check"></i><b>8.2.4</b> Example 1: Continuous predictors</a></li>
<li class="chapter" data-level="8.2.5" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#example-2-categorical-predictors"><i class="fa fa-check"></i><b>8.2.5</b> Example 2: Categorical predictors</a></li>
<li class="chapter" data-level="8.2.6" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#diagnostics"><i class="fa fa-check"></i><b>8.2.6</b> Diagnostics</a></li>
<li class="chapter" data-level="8.2.7" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#anova-and-ancova"><i class="fa fa-check"></i><b>8.2.7</b> ANOVA and ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#logistic-regression"><i class="fa fa-check"></i><b>8.3</b> Logistic regression</a><ul>
<li class="chapter" data-level="8.3.1" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#methodology-1"><i class="fa fa-check"></i><b>8.3.1</b> Methodology</a></li>
<li class="chapter" data-level="8.3.2" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#example-1-continuous-covariates"><i class="fa fa-check"></i><b>8.3.2</b> Example 1: Continuous Covariates</a></li>
<li class="chapter" data-level="8.3.3" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#example-2-categorical-covariates"><i class="fa fa-check"></i><b>8.3.3</b> Example 2: Categorical Covariates</a></li>
<li class="chapter" data-level="8.3.4" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#prediction"><i class="fa fa-check"></i><b>8.3.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#mixed-models"><i class="fa fa-check"></i><b>8.4</b> Mixed Models</a><ul>
<li class="chapter" data-level="8.4.1" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#motivation-1"><i class="fa fa-check"></i><b>8.4.1</b> Motivation</a></li>
<li class="chapter" data-level="8.4.2" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#example-mullen-composite-and-visit"><i class="fa fa-check"></i><b>8.4.2</b> Example: Mullen composite and Visit</a></li>
<li class="chapter" data-level="8.4.3" data-path="regression-analysis-methods.html"><a href="regression-analysis-methods.html#interpreting-results-time-dependent-covariates"><i class="fa fa-check"></i><b>8.4.3</b> Interpreting results: time dependent covariates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html"><i class="fa fa-check"></i><b>9</b> Documenting your results with R Markdown</a><ul>
<li class="chapter" data-level="9.1" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#intro-6"><i class="fa fa-check"></i><b>9.1</b> Intro</a></li>
<li class="chapter" data-level="9.2" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#starting-your-r-markdown"><i class="fa fa-check"></i><b>9.2</b> Starting Your R Markdown</a></li>
<li class="chapter" data-level="9.3" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#understanding-the-r-markdown-editor"><i class="fa fa-check"></i><b>9.3</b> Understanding the R Markdown editor</a><ul>
<li class="chapter" data-level="9.3.1" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#prelude"><i class="fa fa-check"></i><b>9.3.1</b> Prelude</a></li>
<li class="chapter" data-level="9.3.2" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#chunk"><i class="fa fa-check"></i><b>9.3.2</b> Chunk</a></li>
<li class="chapter" data-level="9.3.3" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#non-chunk"><i class="fa fa-check"></i><b>9.3.3</b> Non-chunk</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#creating-your-document-from-the-r-markdown-file"><i class="fa fa-check"></i><b>9.4</b> Creating your document from the R Markdown file</a></li>
<li class="chapter" data-level="9.5" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#creating-tables-with-r-markdown"><i class="fa fa-check"></i><b>9.5</b> Creating tables with R Markdown</a><ul>
<li class="chapter" data-level="9.5.1" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#summary-statistics"><i class="fa fa-check"></i><b>9.5.1</b> Summary statistics</a></li>
<li class="chapter" data-level="9.5.2" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#general-tables"><i class="fa fa-check"></i><b>9.5.2</b> General tables</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="documenting-your-results-with-r-markdown.html"><a href="documenting-your-results-with-r-markdown.html#practice-with-r-markdown"><i class="fa fa-check"></i><b>9.6</b> Practice with R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html"><i class="fa fa-check"></i><b>10</b> Loops and Functional Programming</a><ul>
<li class="chapter" data-level="10.1" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#intro-7"><i class="fa fa-check"></i><b>10.1</b> Intro</a></li>
<li class="chapter" data-level="10.2" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#loops"><i class="fa fa-check"></i><b>10.2</b> Loops</a><ul>
<li class="chapter" data-level="10.2.1" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#example-1-running-many-regression-models"><i class="fa fa-check"></i><b>10.2.1</b> Example 1: Running many regression models</a></li>
<li class="chapter" data-level="10.2.2" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#example-2-the-apply-functions"><i class="fa fa-check"></i><b>10.2.2</b> Example 2: The Apply Functions</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#functional-programming"><i class="fa fa-check"></i><b>10.3</b> Functional Programming</a><ul>
<li class="chapter" data-level="10.3.1" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#example-regression-analysis-as-a-function-call"><i class="fa fa-check"></i><b>10.3.1</b> Example: Regression Analysis as a Function Call</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#simulation-studies"><i class="fa fa-check"></i><b>10.4</b> Simulation Studies</a><ul>
<li class="chapter" data-level="10.4.1" data-path="loops-and-functional-programming.html"><a href="loops-and-functional-programming.html#setting-the-seed-reproducibility-in-simulation-studies"><i class="fa fa-check"></i><b>10.4.1</b> Setting the Seed: Reproducibility in Simulation Studies</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis and Processing with R based on IBIS data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-fundamentals" class="section level1">
<h1><span class="header-section-number">7</span> Statistical Fundamentals</h1>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb357-1" title="1"><span class="kw">library</span>(readr)</a>
<a class="sourceLine" id="cb357-2" title="2"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<div id="intro-4" class="section level2">
<h2><span class="header-section-number">7.1</span> Intro</h2>
<p>This tutorial details fundamental statistical concepts, illustrated with IBIS data. The main purpose is two-fold 1) to develop a set of notation, definitions, and ideas that comprise the foundamentals behind standard statistical analyses and 2) to introduce some basic statistical methods and illustrate how they are carried out in R using IBIS data. The notation and concepts developed here will be referenced again in later tutorials, so those without formal statistical training would be inclined to read this tutorial. For those with a solid background in statistics, this tutorial should serve as a quick refresher as well as an reference for standard statistical terminology and notation.</p>
</div>
<div id="statistical-inference" class="section level2">
<h2><span class="header-section-number">7.2</span> Statistical Inference</h2>
<p>For variable <span class="math inline">\(X\)</span>, its distribution can be thought of as a function which states the probability of <span class="math inline">\(X\)</span> equalling a specific value <span class="math inline">\(x\)</span>, for every possible <span class="math inline">\(x\)</span>. For example, if <span class="math inline">\(X\)</span> is normal distributed, its distribution can be plotted as shown below.</p>
<p><img src="_main_files/figure-html/normal_plot-1.png" width="672" /></p>
<p>We can see that the probability is highest around <span class="math inline">\(x=0\)</span>, and then quickly decreases as you move away from <span class="math inline">\(0\)</span>. When given real data, often a histogram is used to visualize the variable’s distribution. For example, the histogram of AOSI total score 12 months in the AOSI cross sectional data is the following:</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb358-1" title="1">data &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;Data/Cross-sec_full.csv&quot;</span>, <span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>, <span class="dt">na.strings =</span> <span class="kw">c</span>(<span class="st">&quot;.&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot; &quot;</span>))</a>
<a class="sourceLine" id="cb358-2" title="2"><span class="kw">hist</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, <span class="dt">xlab =</span> <span class="st">&quot;AOSI Total Score&quot;</span>,</a>
<a class="sourceLine" id="cb358-3" title="3">     <span class="dt">main=</span><span class="st">&quot;Histogram of AOSI Total Score at 12 months&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/histo_ex-1.png" width="672" /></p>
<p>We can see that it is most likely that AOSI total score will be between 0 and 10, with values higher then 10 unlikely. This type of distribution is called <strong>skewed</strong>, specifically <strong>right skewed</strong> as it has a long “tail” to the right and most of the probability to the left. A <strong>left skewed</strong> distribution is the opposite. We can also consider the distribution of our variable <span class="math inline">\(X\)</span> <strong>conditional</strong> on value <strong>y</strong> of another variable <strong>Y</strong>. Conditional means “only on the population with Y=y”. This is referred to as the <strong>conditional distribution</strong> of <span class="math inline">\(X\)</span> for <span class="math inline">\(Y=y\)</span>. For example, while we have created the histogram of AOSI total score for the entire sample, we may want to visualize the distribution of AOSI total score separately for each of the following diagnosis groups, High Risk: ASD, High Risk: Negative, and Low Risk: Negative. For example, we create the histogram for the High Risk: ASD group below.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb359-1" title="1">data_HRASD &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(GROUP<span class="op">==</span><span class="st">&quot;HR_ASD&quot;</span>)</a>
<a class="sourceLine" id="cb359-2" title="2"><span class="kw">hist</span>(data_HRASD<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, <span class="dt">xlab =</span> <span class="st">&quot;AOSI Total Score&quot;</span>,</a>
<a class="sourceLine" id="cb359-3" title="3">     <span class="dt">main=</span><span class="st">&quot;Conditional Histogram of AOSI Total Score </span><span class="ch">\n</span><span class="st">at 12 months for High Risk: ASD group&quot;</span>) </a></code></pre></div>
<p><img src="_main_files/figure-html/histo_ex2-1.png" width="672" /></p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb360-1" title="1"><span class="co"># can see variable is considered to be a string by default in the data; need to force it to be numeric to create a histogram</span></a></code></pre></div>
<p>Statistical analyses are often designed to <strong>estimate</strong> certain characteristics of a variable’s (or many variables’) distribution. These characteristics are usually referred to as <strong>parameters</strong>. Often times, these parameters are the mean, variance, median/quantiles, or probabilities of specific values (for a discrete variable, i.e., probability of positive ASD diagnosis). We do not know the true values of these parameters, so we try to obtain an accurate approximation of them based on random samples (your data) from the distribution/population of interest. These approximations will vary from sample to sample due to the randomness behind the selection of these samples and their finite size. Thus, we also need to account for the <strong>variance</strong> of these approximations when completing our analyses. This analysis, composed of the <strong>estimation</strong> of the parameters as well as accounting for the <strong>variance</strong> of this estimation, is referred to <strong>statistical inference</strong>.</p>
<div id="parameter-estimation-mean-median-tutorial-quantiles" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Parameter Estimation: Mean, Median, tutorial, Quantiles</h3>
<p>Here, we discuss the estimation of specific parameters that are usually of interest for continuous variables. For categorical variables, see Chapter 6. These parameters are the mean, median, variance, and quantiles. Often, you will see these estimates summarized in “Table 1” in research articles. To see how to create such summaries, see the Chapter 9. Here, we discuss the methodology behind their estimation as well as how to compute these estimates in R.</p>
<p>Both the mean and median can intuitively be thought of as measures of the “center” of the distribution. The variance can be thought of a measure of the “spread” of the distribution. To illustrate variance, we plot two normal distributions both with mean 0 but one with a variance of 1 and another a variance of 4. The increase in the likely range of values with a variance of 4 is quite evident, and the probabilities are more spread out. Note that the <strong>standard deviation</strong> is just the square root of the variance.</p>
<p><img src="_main_files/figure-html/variance_ex-1.png" width="672" /><img src="_main_files/figure-html/variance_ex-2.png" width="672" /></p>
<p>We estimate the distribution’s mean, median, variance, and quantiles using the usual sample mean, median, variance, and quantiles respectively. These can be calculated in R using the functions <strong>mean(), median(), var()</strong>, and <strong>quantile()</strong> respectively. Note: when using quantile(), the minimum and maximum values in the sample are also provided. We illustrate these functions below using AOSI total score at 12 months. Also, note the inclusion of <strong>na.rm=TRUE</strong> into these functions. By default, when calculating these estimates, if a missing value is encountered, R outputs NA (missing). Thus, we need to tell R to remove these missing values before computing the estimates.</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb361-1" title="1"><span class="kw">mean</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## [1] 4.980469</code></pre>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb363-1" title="1"><span class="kw">var</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## [1] 13.08377</code></pre>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" title="1"><span class="kw">median</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb367-1" title="1"><span class="kw">quantile</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##   0%  25%  50%  75% 100% 
##    0    2    4    7   22</code></pre>
<p>However, we often want to see these estimates (and others) for many variables in our dataset without having to calculate each one separately. This can be done using <strong>summary()</strong>. These estimates are often referred to as <strong>summary statistics</strong> of the data. We compute summary statistics for a number of the variables in the dataset below.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb369-1" title="1">data_small &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb369-2" title="2"><span class="st">  </span><span class="kw">select</span>(V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>, V06.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>,</a>
<a class="sourceLine" id="cb369-3" title="3">         V12.aosi.Candidate_Age)</a>
<a class="sourceLine" id="cb369-4" title="4"><span class="kw">summary</span>(data_small)</a></code></pre></div>
<pre><code>##  V12.aosi.total_score_1_18 V06.aosi.total_score_1_18
##  Min.   : 0.00             Min.   : 1.000           
##  1st Qu.: 2.00             1st Qu.: 7.000           
##  Median : 4.00             Median : 9.000           
##  Mean   : 4.98             Mean   : 9.562           
##  3rd Qu.: 7.00             3rd Qu.:12.000           
##  Max.   :22.00             Max.   :28.000           
##  NA&#39;s   :75                NA&#39;s   :105              
##  V12.aosi.Candidate_Age
##  Min.   : 0.00         
##  1st Qu.:12.20         
##  Median :12.50         
##  Mean   :12.59         
##  3rd Qu.:12.90         
##  Max.   :16.70         
##  NA&#39;s   :75</code></pre>
<p>There are also a number of packages which expand R’s functionality in computing these summary statistics. One recommended package is the <strong>Hmisc</strong> package. It includes the function <strong>describe()</strong> which is an improved version of of summary(); describe() is used below with the same variables.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" title="1"><span class="kw">library</span>(Hmisc)</a>
<a class="sourceLine" id="cb371-2" title="2"><span class="kw">describe</span>(data_small)</a></code></pre></div>
<pre><code>## data_small 
## 
##  3  Variables      587  Observations
## ---------------------------------------------------------------------------
## V12.aosi.total_score_1_18 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      512       75       20     0.99     4.98    3.901        1        1 
##      .25      .50      .75      .90      .95 
##        2        4        7       10       12 
##                                                                       
## Value          0     1     2     3     4     5     6     7     8     9
## Frequency     23    51    66    68    72    51    34    40    27    18
## Proportion 0.045 0.100 0.129 0.133 0.141 0.100 0.066 0.078 0.053 0.035
##                                                                       
## Value         10    11    12    13    14    15    16    17    20    22
## Frequency     21    10     8     7     6     4     3     1     1     1
## Proportion 0.041 0.020 0.016 0.014 0.012 0.008 0.006 0.002 0.002 0.002
## ---------------------------------------------------------------------------
## V06.aosi.total_score_1_18 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      482      105       24    0.994    9.562    4.622        4        5 
##      .25      .50      .75      .90      .95 
##        7        9       12       15       17 
## 
## lowest :  1  2  3  4  5, highest: 20 21 22 24 28
## ---------------------------------------------------------------------------
## V12.aosi.Candidate_Age 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      512       75       37    0.994    12.59   0.7036     11.9     12.0 
##      .25      .50      .75      .90      .95 
##     12.2     12.5     12.9     13.4     13.9 
## 
## lowest :  0.0 11.4 11.6 11.7 11.8, highest: 14.9 15.1 15.6 15.9 16.7
## ---------------------------------------------------------------------------</code></pre>
</div>
<div id="accounting-for-estimation-variance-and-hypothesis-testing" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Accounting for estimation variance and hypothesis testing</h3>
<p>While these estimates provide approximations to the parameters of interest, they 1) have some degree of error and 2) vary from sample to sample. To illustrate this, 5 simulated datasets, each of size 100 and with a single variable are generated under a mean of 0. The sample mean is calculated for each of these 5 samples. We see that 1) these sample means differ across the samples and 2) none are exactly 0. Thus, we need to account for this variance when providing the approximations.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb373-1" title="1">data_sim &lt;-<span class="st"> </span><span class="kw">list</span>()</a>
<a class="sourceLine" id="cb373-2" title="2"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){</a>
<a class="sourceLine" id="cb373-3" title="3">  data_sim[[i]] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb373-4" title="4">}</a>
<a class="sourceLine" id="cb373-5" title="5"></a>
<a class="sourceLine" id="cb373-6" title="6"><span class="kw">lapply</span>(data_sim, mean)</a></code></pre></div>
<pre><code>## [[1]]
## [1] -0.008324844
## 
## [[2]]
## [1] 0.07970222
## 
## [[3]]
## [1] 0.03900914
## 
## [[4]]
## [1] -0.1174177
## 
## [[5]]
## [1] 0.04604559</code></pre>
</div>
<div id="confidence-intervals" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Confidence intervals</h3>
<p>This is generally done by including a <strong>confidence interval</strong> with your approximation, more specially a <strong><span class="math inline">\(x\)</span>% confidence interval</strong> where <span class="math inline">\(x\)</span> is some number between 0 and 100. Intuitively, you can interpret a confidence interval as a “reasonable” range of values for your parameter of interest based on your data. Increasing the percentage of the confidence interval increases its width, and thus increases the chances that the confidence interval from a sample will contain the true parameter. However, this increasing width also decreases the precision of the information you receive from the confidence interval, so there is a trade off. Generally, 95% is used (though this is just convention).</p>
<p>As an example, we considering computing a confidence interval for the mean. Consider AOSI total score at 12 months from our dataset. We have already computed an estimate of the mean; let us add a confidence interval to this estimate. This can be done using the <strong>t.test()</strong> function (which has other uses which we cover later).</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb375-1" title="1"><span class="kw">t.test</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  data$V12.aosi.total_score_1_18
## t = 31.156, df = 511, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  4.666411 5.294526
## sample estimates:
## mean of x 
##  4.980469</code></pre>
<p>Let us focus on the bottom of the output for now; we cover the top later. We see that we approximate that the mean AOSI total score at 12 months in the population is 4.98 and a reasonable set of values for this mean in the population is 4.67 to 5.29 using a 95% confidence interval.</p>
</div>
<div id="hypothesis-testing" class="section level3">
<h3><span class="header-section-number">7.2.4</span> Hypothesis testing</h3>
<p>In order to come to a conclusion about a paramater from the sample information, hypothesis testing is generally used.</p>
<p>The setup is the following: suppose we are interested in inferring if the mean for a variable is some value, say <span class="math inline">\(\mu_0\)</span>. From the data we have, we would like to make an educated guess about the claim that the mean is <span class="math inline">\(\mu_0\)</span>. The main principle in scientific research is that one makes a claim or hypothesis, conducts an experiment, and sees if the results of the experiment contradict the claim. This is the same reasoning that governs hypothesis testing.</p>
<p>To start, we make a claim which we would “like” to refute (for example, a treatment has no effect). This claim is referred to as the null hypothesis. For example, consider the null hypothesis that the mean is <span class="math inline">\(\mu_0\)</span>. We then define the contradiction to this claim, that the mean is NOT <span class="math inline">\(\mu_0\)</span>, as the alternative hypothesis. Finally, we take the information from our data, and see if there is enough evidence to <strong>reject</strong> the null hypothesis in favor of the alternative. If there is not enough evidence, then we <strong>fail to reject</strong> the null. That is, we <strong>never</strong> accept the null or prove that the null is true. Recall that the null is our baseline claim that we are aiming to refute; if we accepted the null, then we would be “proving true” that which we initially claimed to hold.</p>
<p>How do we determine if we have “enough evidence” to reject the null? The following process is generally used. First, we reduce our data down to a single value that is related to the hypothesis being tested. This value is called a <strong>test statistic</strong>. Then, we see how much the observed test statistic from our data deviates from the range of values we would expect if the null hypothesis were true. If this deivation is large enough, we decide to reject the null. Otherwise, we fail to reject.</p>
<p>This is best explained by example. Consider our null hypothesis of the mean is <span class="math inline">\(\mu_0\)</span>. Intuitively, we would calculate the sample mean and use it as our test statistic, and compare its value to <span class="math inline">\(\mu_0\)</span>. If the sample mean is “close” to <span class="math inline">\(\mu_0\)</span>, we would fail to reject, otherwise we would reject. For example, recall that for AOSI total score at 12 months, the sample mean ws 4.98. For our null hypothesis was that the population mean was <span class="math inline">\(\mu_0\)</span>=5, we probably would not have enough evidence reject the null. However, we need a formal way of measuring the deviation from the null, preferrably one that is independent of the variable’s units. The <strong>p-value</strong> serves as this measure.</p>
<p>Formally, the p-value measures the probability of seeing a test statistic value that is as extreme or more extreme from the null hypothesis then the test statistic value you actually observed. Informally, you can think of a p-value as a unit agnostic measure of how much your data deivates from the null hypothesis. We calculate the p-value using the observed value of the test statistic as well as the <strong>test statistic’s distribution</strong> (also referred to as its <strong>sampling distribution</strong>); this distribution is how we are able to compute the probablity which the p-value reflects.</p>
<p>To conduct the hypothesis test corresponding to the null hypothesis that the population mean is 0, a <strong>one sample t-test</strong> is often used. We will cover this in more detail later; here we use it to illustrate the above concepts. The t.test() function can also be used to conduct this hypothesis test. We consider testing if the mean AOSI total score at 12 months is 0. Note that we can choose a values different from 0 to use in our null hypothesis by adding the argument mu=x, where x is the value of interest.</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb377-1" title="1"><span class="kw">t.test</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  data$V12.aosi.total_score_1_18
## t = 31.156, df = 511, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  4.666411 5.294526
## sample estimates:
## mean of x 
##  4.980469</code></pre>
<p>The top part of the output contains the hypothesis test results. We see that the test statistic (denoted by t) is 31.156 and the corresponding p-value is essentially 0. Note that <strong>there is a one to one correspondence between the test statistic value and the p-value</strong>. Thus, reporting the p-value only is sufficient. We see that the p-value is very small; a small p-value implies that the data deviates from the null. However, to make a reject or fail to reject decision, we have to set a threshold for this p-value. Generally, people select 0.05 as a threshold; below 0.05 implies the evidence is strong enough to reject and above 0.05 implies the evidence is not strong enough. However this is <strong>just a rule of thumb</strong> and one could justify a different threshold.</p>
<p>Furthermore, it may not be wise to make an all or nothing decision in terms of judging the scientific value of the results. Using a p-value threshold implies that a p-value of 0.051 has the same interpretation as a p-vale of 0.51 and that a p-value of 0.049 is “significant” evidence while a p-value of 0.051 is not. This dramatically limits the scientific information that the results are providing. Instead, it is better to interpret p-values more broadly and in terms of their strength of evidence. For example, a p-value of 0.06 or 0.025 may indicate “strong evidence” in favor of the alternative hypothesis and 0.10 or 0.12 may indicate “moderate evidence”. Simply reducing the interpretation to “significant” or “not significant” is not optimal and should be avoided.</p>
</div>
<div id="hypothesis-testing-with-means" class="section level3">
<h3><span class="header-section-number">7.2.5</span> Hypothesis Testing with Means</h3>
<p>Here we cover methods to conduct hypothesis testing with population means. You will likely recognize many of these methods; we cover <strong>t-tests</strong> and <strong>ANOVA</strong>. We illustrate these using AOSI total score at 12 months and diagnosis group (High Risk: ASD, High Risk: Negative, Low Risk: Negative)</p>
<div id="t-tests-one-sample-and-two-sample" class="section level4">
<h4><span class="header-section-number">7.2.5.1</span> T-tests: One Sample and Two Sample</h4>
<p>First, consider testing the null hypothesis that the mean AOSI total score at 12 months is 0 in the population. As discussed before, this comparison of a single mean to a value is generally done with a <strong>one sample t-test</strong>. Recall that anytime we do a hypothesis test, we require the following:
1) Test statistic
2) Distribution of the test statistic
3) P-value from this distribution and the test statistic’s observed value</p>
<p>In this case, the test statistic is denoted by <span class="math inline">\(T\)</span> since it has a <strong><span class="math inline">\(T\)</span> distribution</strong>. This test statistic <span class="math inline">\(T\)</span> is equal to the sample mean minus the null value (often 0) and then divided by the spread of the sample mean (called <strong>standard error</strong>). <span class="math inline">\(T\)</span> distributions are differentiated by the parameter called <strong>degrees of freedom</strong> (similar to how normal distributions are differentiated by their mean and variance). Using the value of <span class="math inline">\(T\)</span> with the value of the degrees of freedom and the <span class="math inline">\(T\)</span> distribution, components 1) and 2), we can calculate a p-value. All three of these components are provided in the output from t.test(), along with the alternative hypothesis of the test (that the mean is not 0).</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb379-1" title="1"><span class="kw">t.test</span>(data<span class="op">$</span>V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  data$V12.aosi.total_score_1_18
## t = 31.156, df = 511, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  4.666411 5.294526
## sample estimates:
## mean of x 
##  4.980469</code></pre>
<p>We see that under a p-value of about 0, we have strong evidence in favor of the mean AOSI total score at 12 months not equalling 0. Note that you can also see that 0 is quite outside the 95% confidence interval, indicating that 0 is not a reasonable value for the population mean based on this dataset (which points to the alternative hypothesis). It turns out that p-values and confidence intervals are generally linked together and will agree in this fashion <strong>by their design</strong>.</p>
<p>Note that for this process to be valid, some assumptions are made. They are a) AOSI total score at 12 months is normally distributed and b) all observations are independent. If one or more of these is violated, the results from your one-sample t-test will be invalid.</p>
<p>Now suppose we wanted to compare mean AOSI total score at 12 months between two diagnosis groups, such as High Risk: ASD and High Risk: Negative. Specifically, the null hypothesis will be that the means are the same between the two groups. The common corresponding test is called a <strong>two sample t-test</strong>. Again, we use the function t.test(). Here, we use y~x notation where x is the grouping variable to do the two sample test. You will again obtain a test statistic t, degrees of freedom, and a p-value. As in the one sample case, this test statistic also has a <span class="math inline">\(T\)</span> distribution.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb381-1" title="1">data_HR &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb381-2" title="2"><span class="st">  </span><span class="kw">filter</span>(GROUP<span class="op">==</span><span class="st">&quot;HR_ASD&quot;</span><span class="op">|</span>GROUP<span class="op">==</span><span class="st">&quot;HR_neg&quot;</span>)</a>
<a class="sourceLine" id="cb381-3" title="3"></a>
<a class="sourceLine" id="cb381-4" title="4"><span class="kw">t.test</span>(V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span><span class="op">~</span>GROUP,<span class="dt">data=</span>data_HR)</a></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  V12.aosi.total_score_1_18 by GROUP
## t = 4.9977, df = 113.84, p-value = 2.119e-06
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.506931 3.486090
## sample estimates:
## mean in group HR_ASD mean in group HR_neg 
##             7.337500             4.840989</code></pre>
<p>You can see R provides the following, starting from the top.
1) Test statistic t, degrees of freedom, and p-value
2) alternative hypothesis
3) 95% confidence interval for the <strong>difference in the means</strong>
4) sample means for each group</p>
<p>We see that, as expected, based on a p-value about 0, we have strong evidence that the mean AOSI total scores at 12 months are different between High Risk: ASD and High Risk: Negative. This can also be seen in 0 being far away from the confidence interval and the sample means of 7.34 and 4.84 being quite different from one another.</p>
</div>
<div id="anova" class="section level4">
<h4><span class="header-section-number">7.2.5.2</span> ANOVA</h4>
<p>Suppose we want to compare more then two groups’ means. For example, suppose we want to compare the mean AOSI total score at 12 months for the High Risk: ASD, High Risk: Negative, and Low Risk: Negative groups. This is done using an <strong>ANOVA F test</strong>. The null hypothesis is that the mean AOSI total score at 12 months is same in all three groups. The alternative is that at least one group’s mean differs from the rest. We can conduct this test in R using <strong>aov()</strong>. Again, it uses formula notation (y~x). We conduct this test below. Note that many components are calculated by R for this test. To obtain the main values of interest, we must save the output as an object (which stores all of the components) and then use the function <strong>summary()</strong> on this object.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb383-1" title="1">aov_object &lt;-<span class="st"> </span><span class="kw">aov</span>(V12.aosi.total_score_<span class="dv">1</span>_<span class="dv">18</span><span class="op">~</span>GROUP, <span class="dt">data=</span>data)</a>
<a class="sourceLine" id="cb383-2" title="2"><span class="kw">summary</span>(aov_object)</a></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## GROUP         3    599  199.81   16.68 2.39e-10 ***
## Residuals   508   6086   11.98                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 75 observations deleted due to missingness</code></pre>
<p>We see degrees of freedom are provided (3 and 508 in this example), the value of the test statistic (F value=16.68) and the corresponding p-value (2.39e-10 or essentially 0). For an ANOVA F test, the test statistic <span class="math inline">\(F\)</span> has an <span class="math inline">\(F\)</span> distribution. An <span class="math inline">\(F\)</span> distribution is defined by two degrees of freedom parameters. Using this F statistic value and F distribution, the p-value can be calculated.</p>
<p>While an ANOVA F test will infer if the groups differ overall, we would like to see <strong>which</strong> groups differ. This generally done by doing all of the pairwise comparisons. For our example, that would entail hypothesis tests for 1) HR: ASD vs HR: Negative, 2) HR: ASD vs LR: Negative, 3) HR: Negative vs LR: Negative, etc. for 6 total tests. Recall when comparing two groups’ means, we can use a two sample t-test. For each pairwise test, we use this two sample t-test. Then, we interpret the test results for each pair separately. This is frequently referred to as <strong>post-hoc</strong> analysis. It turns out that because we are conducting multiple hypothesis tests at once, we need to “correct” each p-value from these pairwise comparisons to account for this <strong>multiple comparison</strong>. Why this is the case is beyond the scope of these tutorials. Generally, the correction done is called <strong>Tukey’s Method</strong>, though other corrections such as <strong>Bonferroni</strong> or <strong>Holm’s Method</strong> can also be used. These <strong>corrected p-values</strong> can then be “validly” interpreted like usual p-values. To compute this post-hoc analysis in R using Tukey’s Method, use the function <strong>TukeyASD()</strong> with the object from aov().</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb385-1" title="1"><span class="kw">TukeyHSD</span>(aov_object)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = V12.aosi.total_score_1_18 ~ GROUP, data = data)
## 
## $GROUP
##                     diff       lwr         upr     p adj
## HR_neg-HR_ASD -2.4965106 -3.626229 -1.36679183 0.0000001
## LR_ASD-HR_ASD -3.6708333 -8.917563  1.57589610 0.2728961
## LR_neg-HR_ASD -3.3511986 -4.592245 -2.11015217 0.0000000
## LR_ASD-HR_neg -1.1743227 -6.352589  4.00394397 0.9367305
## LR_neg-HR_neg -0.8546880 -1.763793  0.05441738 0.0740168
## LR_neg-LR_ASD  0.3196347 -4.884054  5.52332358 0.9985859</code></pre>
<p>The output contains the following:
1) Difference in sample means between the groups (diff)
2) 95% confidence intervals for each mean difference (lwr and upr)
3) Corrected p-values for each pairwise comparison (p adj)</p>
<p>This entire ANOVA analysis provides valid results under the following assumptions
1) All groups’ values are normally distributed <strong>with the same variance</strong>
2) All observations are independent (both within the groups and between the groups)</p>
<p>The first assumption can be checked visually using a histogram and by estimating the variances with confidence intervals, or conducting hypothesis tests for equal variances (not covered here). The second assumption is verified based on the study from which the data originated.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="working-with-tables-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-analysis-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
